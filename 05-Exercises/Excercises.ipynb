{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `titanic.xls` spreadsheet in the `data` directory contains data regarding the passengers on the Titanic when it sank in 1912. A recent [Kaggle competition](http://www.kaggle.com/c/titanic-gettingStarted) was based on predicting survival for passengers based on the attributes in the passenger list. \n",
    "\n",
    "Use scikit-learn to build a KNN classifier, a Decision Tree and an Ensemble model to predict survival on the Titanic. Use cross-validation to assess your models, and try to tune them to improve performance.\n",
    "\n",
    "Discuss the benefits and drawbacks of all approaches for application to such problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given breast cancer Wisconsin dataset in scikit-learn solve a tipical binary classification problem. \n",
    "\n",
    "The idea is to use all the tools we introduced so far in the class to find the best solution possible. In particular, the exercise should involve the following steps:\n",
    "\n",
    "\n",
    "1. **Import libraries, load the data**\n",
    "\n",
    "2. **Exploration and preparation**\n",
    "\n",
    "    * check the imbalance in data\n",
    "    * check missing values\n",
    "    * understand the data better using plots\n",
    "    * make some hypothesis using the plots and try to make some features representing them. Note that these features might/might not work because they are just hypothesis. \n",
    "\n",
    "3. **Train a Decision Tree classifier and an Ensemble classifier **\n",
    "\n",
    "4. **Evaluate the performance of the classifier**\n",
    "\n",
    "5. **Optimization**\n",
    "\n",
    "6. **Train an alternative classifier (K-NN) and repeat steps 4-5**\n",
    "\n",
    "7. **Explore the sensitivity to the parameters `max_features`, the number of variables considered for splitting at each step, `max_depth`, the maximum depth of the tree, and `n_estimators`, the number of trees in the forest (when applies). Use apprpriate metrics of performance, and include plots against a suitably-chosen range of values for these parameters**\n",
    "\n",
    "8. **Decide wich approach to use if you were asked to solve the problem in a real case**\n",
    "\n",
    "Dataset description: Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "- `radius` (mean of distances from center to points on the perimeter) \n",
    "- `texture` (standard deviation of gray-scale values) \n",
    "- `perimeter` \n",
    "- `area` \n",
    "- `smoothness` (local variation in radius lengths) \n",
    "- `compactness` (perimeter^2 / area - 1.0) \n",
    "- `concavity` (severity of concave portions of the contour) \n",
    "- `concave points` (number of concave portions of the contour) \n",
    "- `symmetry` \n",
    "- `fractal dimension` (\"coastline approximation\" - 1)\n",
    "\n",
    "The outcome to be predicted is tumor type (M = malignant, B = benign)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer here\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Use a grid search to optimize the number of estimators and max_depth for a Gradient Boosted Decision tree using the Wisconsin breast cancer data. Plug this optimal ``max_depth`` into a *single* decision tree.  Does this single tree over-fit or under-fit the data? Repeat this for the Random Forest.  Construct a single decision tree using the ``max_depth`` which is optimal for the Random Forest.  Does this single tree over-fit or under-fit the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
